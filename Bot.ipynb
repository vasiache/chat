{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from aiogram import Bot, types\n",
    "from aiogram.dispatcher import Dispatcher\n",
    "from aiogram.utils import executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_token = \"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\"\n",
    "tg_token=\"5984179394:AAEpplgueY6_wlgMllafDxkO_kLIcVdsfHQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=open_ai_token\n",
    "bot=Bot(tg_token)\n",
    "dp=Dispatcher(bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dp.message_handler()\n",
    "async def send(message : types.Message):\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Convert this text to a programmatic command:\\n\\nExample: Ask Constance if we need some bread\\nOutput: send-msg `find constance` Do we need some bread?\\n\\nReach out to the ski store and figure out if I can get my skis fixed before I leave on Thursday\",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.2,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\n\"])\n",
    "    await message.answer(response['choices'][0]['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/site-packages/aiogram/utils/executor.py:320\u001b[0m, in \u001b[0;36mExecutor.start_polling\u001b[0;34m(self, reset_webhook, timeout, relax, fast, allowed_updates)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     loop\u001b[39m.\u001b[39;49mrun_until_complete(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_startup_polling())\n\u001b[1;32m    321\u001b[0m     loop\u001b[39m.\u001b[39mcreate_task(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher\u001b[39m.\u001b[39mstart_polling(reset_webhook\u001b[39m=\u001b[39mreset_webhook, timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    322\u001b[0m                                                    relax\u001b[39m=\u001b[39mrelax, fast\u001b[39m=\u001b[39mfast, allowed_updates\u001b[39m=\u001b[39mallowed_updates))\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/asyncio/base_events.py:592\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 592\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    594\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/asyncio/base_events.py:552\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 552\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/vasche/workspace/git/ChatGPT/Bot.ipynb Ячейка 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vasche/workspace/git/ChatGPT/Bot.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m executor\u001b[39m.\u001b[39;49mstart_polling(dp, skip_updates\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/site-packages/aiogram/utils/executor.py:45\u001b[0m, in \u001b[0;36mstart_polling\u001b[0;34m(dispatcher, loop, skip_updates, reset_webhook, on_startup, on_shutdown, timeout, relax, fast, allowed_updates)\u001b[0m\n\u001b[1;32m     42\u001b[0m executor \u001b[39m=\u001b[39m Executor(dispatcher, skip_updates\u001b[39m=\u001b[39mskip_updates, loop\u001b[39m=\u001b[39mloop)\n\u001b[1;32m     43\u001b[0m _setup_callbacks(executor, on_startup, on_shutdown)\n\u001b[0;32m---> 45\u001b[0m executor\u001b[39m.\u001b[39;49mstart_polling(\n\u001b[1;32m     46\u001b[0m     reset_webhook\u001b[39m=\u001b[39;49mreset_webhook,\n\u001b[1;32m     47\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m     48\u001b[0m     relax\u001b[39m=\u001b[39;49mrelax,\n\u001b[1;32m     49\u001b[0m     fast\u001b[39m=\u001b[39;49mfast,\n\u001b[1;32m     50\u001b[0m     allowed_updates\u001b[39m=\u001b[39;49mallowed_updates\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/site-packages/aiogram/utils/executor.py:328\u001b[0m, in \u001b[0;36mExecutor.start_polling\u001b[0;34m(self, reset_webhook, timeout, relax, fast, allowed_updates)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     loop\u001b[39m.\u001b[39;49mrun_until_complete(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_polling())\n\u001b[1;32m    329\u001b[0m     log\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mGoodbye!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/asyncio/base_events.py:592\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \n\u001b[1;32m    583\u001b[0m \u001b[39mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 592\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    594\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n\u001b[1;32m    595\u001b[0m future \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39mensure_future(future, loop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/.venvTorch/lib/python3.8/asyncio/base_events.py:552\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    551\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 552\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    553\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "executor.start_polling(dp, skip_updates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54405e3b80a0470a0a6a6417e844dc60f4262de3ef785371b276dbe20f0236a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
